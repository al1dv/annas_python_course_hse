{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1: выгрузка файлов"
      ],
      "metadata": {
        "id": "aa2G_JERA7yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Зайдите в репозиторий датасетов для обучения диалоговых систем\n",
        "2. Найдите все файлы с расширением *.txt (их всего 5 в репозитории)\n",
        "3. Выгрузите каждый файл с помощью утилиты `wget`\n",
        "- Для этого откройте датасет в браузере, например, https://github.com/Phylliida/Dialogue-Datasets/blob/master/TwitterLowerAsciiCorpus.txt\n",
        "- Затем найдите кнопку `raw`, которая откроет вам файл \"как есть\" (как в блокноте!)\n",
        "- Скопируйте ссылку на файл (она выглядит так: https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt)\n",
        "- Воспользуйтесь `wget`\n",
        "---\n",
        "Как использовать `wget`:\n",
        "---"
      ],
      "metadata": {
        "id": "vrtdr5UF_TyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swBssiVj90wr",
        "outputId": "408bab5c-f39c-4d49-8f5e-c59c23141608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 12:26:18--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘twitter.txt’\n",
            "\n",
            "\rtwitter.txt           0%[                    ]       0  --.-KB/s               \rtwitter.txt         100%[===================>] 579.79K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-12-05 12:26:18 (59.1 MB/s) - ‘twitter.txt’ saved [593707/593707]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O twitter.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь:\n",
        "- ! указывает на то, что это консольная утилита, а не код на python\n",
        "- после wget идет полный адрес ссылки для скачивания файла\n",
        "- после параметра `-O` указываем название файла, под которым мы хотим скачать файл"
      ],
      "metadata": {
        "id": "kekDrEGyAXUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь: повторите процедуру для остальных файлов (всего должно быть 5 файлов)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt -O twitter_corpus.txt\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt -O movie_corpus.txt\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt -O words_corpus.txt\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt -O bnc_corpus.txt\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O twitter.txt"
      ],
      "metadata": {
        "id": "1FAveoWrAWm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf68494-a142-4711-8d69-35453ee43d69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 18:38:41--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 612338 (598K) [text/plain]\n",
            "Saving to: ‘twitter_corpus.txt’\n",
            "\n",
            "twitter_corpus.txt  100%[===================>] 597.99K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-12-05 18:38:41 (11.1 MB/s) - ‘twitter_corpus.txt’ saved [612338/612338]\n",
            "\n",
            "--2025-12-05 18:38:41--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16976724 (16M) [text/plain]\n",
            "Saving to: ‘movie_corpus.txt’\n",
            "\n",
            "movie_corpus.txt    100%[===================>]  16.19M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-05 18:38:42 (142 MB/s) - ‘movie_corpus.txt’ saved [16976724/16976724]\n",
            "\n",
            "--2025-12-05 18:38:42--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19173003 (18M) [text/plain]\n",
            "Saving to: ‘words_corpus.txt’\n",
            "\n",
            "words_corpus.txt    100%[===================>]  18.28M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-05 18:38:43 (166 MB/s) - ‘words_corpus.txt’ saved [19173003/19173003]\n",
            "\n",
            "--2025-12-05 18:38:43--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19081694 (18M) [text/plain]\n",
            "Saving to: ‘bnc_corpus.txt’\n",
            "\n",
            "bnc_corpus.txt      100%[===================>]  18.20M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-05 18:38:44 (174 MB/s) - ‘bnc_corpus.txt’ saved [19081694/19081694]\n",
            "\n",
            "--2025-12-05 18:38:44--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘twitter.txt’\n",
            "\n",
            "twitter.txt         100%[===================>] 579.79K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-12-05 18:38:44 (21.7 MB/s) - ‘twitter.txt’ saved [593707/593707]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2: открываем файлы"
      ],
      "metadata": {
        "id": "JLaq0LFXBBI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изучите туториал по работе с файлами, который вы получили в чате. Каждый файл нужно теперь открыть, а его содержание - записать в переменную *любым удобным вам способом*\n",
        "\n",
        "Пример:"
      ],
      "metadata": {
        "id": "AjNtW5R1BI7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('twitter.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "_uJqiGUpBFEV",
        "outputId": "b788e2f0-5404-4596-b2d3-4771b9c0ac82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь: откройте все файлы, выведите на экран их размер и первые 100 символов (всего должно быть обработано 5 файлов)\n",
        "file = open('twitter.txt', 'r', encoding='utf-8')\n",
        "dataset_content0 = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content0)} символов\")\n",
        "dataset_content0[:100]"
      ],
      "metadata": {
        "id": "yrYxdTj6BGv_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e73c0b84-d19f-4734-856c-36174e45a9d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('twitter_corpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content1 = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content1)} символов\")\n",
        "dataset_content1[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "8jMI-lLY16EM",
        "outputId": "92cd0112-7f02-4ba4-b9f3-7a613ed970cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 598556 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on Twitter? Haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('movie_corpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content2 = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content2)} символов\")\n",
        "dataset_content2[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "2RMx7WZb19kx",
        "outputId": "cb8d6483-77e1-4053-f991-0a0c59ca1684"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 16976724 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Colonel Durnford... William Vereker. I hear you 've been seeking Officers?\\nGood ones, yes, Mr Vereke\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('words_corpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content3 = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content3)} символов\")\n",
        "dataset_content3[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "gh1puM3O2Ap8",
        "outputId": "3fd9b903-28aa-4018-b566-720520383f35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 19173003 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You enjoyed yourself in America\\nEh\\ndid you\\nOh I covered a nice trip yes\\nOh very good\\nsaw Mary and An'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('bnc_corpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content4 = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content4)} символов\")\n",
        "dataset_content4[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "g2L_0FKg2DMr",
        "outputId": "be755735-17dd-4ee4-b458-27edeef15e99"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 19081694 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You enjoyed yourself in America\\nEh\\ndid you\\nOh I covered a nice tripyes\\nOh very good\\nsaw Mary and And'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 3: первичный анализ"
      ],
      "metadata": {
        "id": "vSc5RUhgBu_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем статистику для каждого файла по образцу:"
      ],
      "metadata": {
        "id": "ui-vA_4wB76-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open('twitter.txt', 'r', encoding='utf-8') as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(all_lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_chars += len(line)\n",
        "\n",
        "    words_in_line = line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line.strip():\n",
        "      non_empty_lines += 1\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "max_line_length = max([len(line) for line in all_lines])\n",
        "min_line_length = min([len(line) for line in all_lines])\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XliSd4K4Byym",
        "outputId": "66c13d54-1368-4335-f719-dd7123b95527"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16556\n",
            "Непустых строк: 10514\n",
            "Всего слов: 112977\n",
            "Всего символов: 593707\n",
            "Макс. длина строки: 147\n",
            "Мин. длина строки: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open('twitter_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(all_lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_chars += len(line)\n",
        "\n",
        "    words_in_line = line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line.strip():\n",
        "      non_empty_lines += 1\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "max_line_length = max([len(line) for line in all_lines])\n",
        "min_line_length = min([len(line) for line in all_lines])\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjha2UDL57dq",
        "outputId": "d7f57111-0eef-4489-d8ec-2547b5fc0bd9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16556\n",
            "Непустых строк: 10628\n",
            "Всего слов: 114910\n",
            "Всего символов: 598556\n",
            "Макс. длина строки: 147\n",
            "Мин. длина строки: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open('words_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(all_lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_chars += len(line)\n",
        "\n",
        "    words_in_line = line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line.strip():\n",
        "      non_empty_lines += 1\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "max_line_length = max([len(line) for line in all_lines])\n",
        "min_line_length = min([len(line) for line in all_lines])\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYfVXTHI6HWW",
        "outputId": "56a9db2c-4024-4e2a-8ad4-b159c2c71a7d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 611014\n",
            "Непустых строк: 606486\n",
            "Всего слов: 4052241\n",
            "Всего символов: 19173003\n",
            "Макс. длина строки: 2774\n",
            "Мин. длина строки: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open('movie_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(all_lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_chars += len(line)\n",
        "\n",
        "    words_in_line = line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line.strip():\n",
        "      non_empty_lines += 1\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "max_line_length = max([len(line) for line in all_lines])\n",
        "min_line_length = min([len(line) for line in all_lines])\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "id": "z25I60pI6QTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open('bnc_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(all_lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_chars += len(line)\n",
        "\n",
        "    words_in_line = line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line.strip():\n",
        "      non_empty_lines += 1\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "max_line_length = max([len(line) for line in all_lines])\n",
        "min_line_length = min([len(line) for line in all_lines])\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GH921qa6d2a",
        "outputId": "f3863fc1-33fd-452d-9d1f-64d38fc67e8a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 611014\n",
            "Непустых строк: 606486\n",
            "Всего слов: 3719853\n",
            "Всего символов: 19081694\n",
            "Макс. длина строки: 2703\n",
            "Мин. длина строки: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4: чистка текста"
      ],
      "metadata": {
        "id": "aptZI3yhEOlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines0 = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words0 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "with open('twitter.txt', 'r', encoding='utf-8') as file:\n",
        "  for line in file:\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "    line = line.strip()\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "# 3. Убираем лишние пробелы\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "# 4. Приводим к нижнему регистру\n",
        "    line = line.lower()\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "    if line:\n",
        "      cleaned_lines0.append(line)\n",
        "      words = line.split()\n",
        "      for word in words:\n",
        "        if len(words) > 1:\n",
        "          all_cleaned_words0.append(word)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines0[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDEshS1DMo4",
        "outputId": "47fae2e2-c9f3-45cb-e9a9-9ba2263d9024"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: whats up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 111670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines1 = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words1 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "with open('twitter_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "  for line in file:\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "    line = line.strip()\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "# 3. Убираем лишние пробелы\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "# 4. Приводим к нижнему регистру\n",
        "    line = line.lower()\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "    if line:\n",
        "      cleaned_lines1.append(line)\n",
        "      words = line.split()\n",
        "      for word in words:\n",
        "        if len(words) > 1:\n",
        "          all_cleaned_words1.append(word)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines1[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfB25L9T9N3z",
        "outputId": "30cb8ea9-01dd-4877-babe-e57c34a23abe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: whats up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 111674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines2 = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words2 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "with open('movie_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "  for line in file:\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "    line = line.strip()\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "# 3. Убираем лишние пробелы\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "# 4. Приводим к нижнему регистру\n",
        "    line = line.lower()\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "    if line:\n",
        "      cleaned_lines2.append(line)\n",
        "      words = line.split()\n",
        "      for word in words:\n",
        "        if len(words) > 1:\n",
        "          all_cleaned_words2.append(word)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines2[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a5KykIj9a9k",
        "outputId": "5d7b3f77-d245-40bb-b510-7c1642cb7b12"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: colonel durnford william vereker i hear you ve been seeking officers...\n",
            "Всего очищенных слов: 3153343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines3 = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words3 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "with open('words_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "  for line in file:\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "    line = line.strip()\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "# 3. Убираем лишние пробелы\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "# 4. Приводим к нижнему регистру\n",
        "    line = line.lower()\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "    if line:\n",
        "      cleaned_lines3.append(line)\n",
        "      words = line.split()\n",
        "      for word in words:\n",
        "        if len(words) > 1:\n",
        "          all_cleaned_words3.append(word)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines3[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za3JRMlG9rCg",
        "outputId": "67013b89-dbab-445a-bbf0-7829b55696b7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 3927654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines4 = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words4 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "with open('bnc_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "  for line in file:\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "    line = line.strip()\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "# 3. Убираем лишние пробелы\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "# 4. Приводим к нижнему регистру\n",
        "    line = line.lower()\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "    if line:\n",
        "      cleaned_lines4.append(line)\n",
        "      words = line.split()\n",
        "      for word in words:\n",
        "        if len(words) > 1:\n",
        "          all_cleaned_words4.append(word)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines4[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gyto0QFA96GB",
        "outputId": "cd7b8e74-483d-45c1-dcc9-9699386a31b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 3586641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 5: статистика"
      ],
      "metadata": {
        "id": "WvPQoLBzGvAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 1: получаем статистику распределений длин слов"
      ],
      "metadata": {
        "id": "Iirxb-yneJqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words0)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "for word in all_cleaned_words0:\n",
        "    word_lengths.append(len(word))\n",
        "    total_chars += len(word)\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "#                если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "  if length in word_length_count:\n",
        "    word_length_count[length] += 1\n",
        "#                иначе: выполняем >\n",
        "  else:\n",
        "    word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Z1tTq5DQFA",
        "outputId": "bc29d515-2e50-418f-830a-e7c7fee8d2c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 111670\n",
            "Символов после очистки: 448546\n",
            "Распределение длин слов:\n",
            "  1 букв: 7238 слов\n",
            "  2 букв: 19570 слов\n",
            "  3 букв: 24657 слов\n",
            "  4 букв: 25365 слов\n",
            "  5 букв: 13201 слов\n",
            "  6 букв: 7860 слов\n",
            "  7 букв: 6048 слов\n",
            "  8 букв: 3448 слов\n",
            "  9 букв: 2035 слов\n",
            "  10 букв: 1106 слов\n",
            "  11 букв: 529 слов\n",
            "  12 букв: 266 слов\n",
            "  13 букв: 145 слов\n",
            "  14 букв: 75 слов\n",
            "  15 букв: 43 слов\n",
            "  16 букв: 27 слов\n",
            "  17 букв: 15 слов\n",
            "  18 букв: 9 слов\n",
            "  19 букв: 11 слов\n",
            "  20 букв: 4 слов\n",
            "  21 букв: 2 слов\n",
            "  22 букв: 3 слов\n",
            "  23 букв: 1 слов\n",
            "  24 букв: 1 слов\n",
            "  25 букв: 3 слов\n",
            "  26 букв: 1 слов\n",
            "  27 букв: 2 слов\n",
            "  28 букв: 2 слов\n",
            "  33 букв: 1 слов\n",
            "  51 букв: 1 слов\n",
            "  98 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words1)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "for word in all_cleaned_words1:\n",
        "    word_lengths.append(len(word))\n",
        "    total_chars += len(word)\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "#                если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "  if length in word_length_count:\n",
        "    word_length_count[length] += 1\n",
        "#                иначе: выполняем >\n",
        "  else:\n",
        "    word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6ETfaM3_1tY",
        "outputId": "697f7708-917b-4a2c-da32-04a8ca959bc0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 111674\n",
            "Символов после очистки: 448566\n",
            "Распределение длин слов:\n",
            "  1 букв: 7239 слов\n",
            "  2 букв: 19570 слов\n",
            "  3 букв: 24657 слов\n",
            "  4 букв: 25365 слов\n",
            "  5 букв: 13201 слов\n",
            "  6 букв: 7862 слов\n",
            "  7 букв: 6049 слов\n",
            "  8 букв: 3448 слов\n",
            "  9 букв: 2035 слов\n",
            "  10 букв: 1106 слов\n",
            "  11 букв: 529 слов\n",
            "  12 букв: 266 слов\n",
            "  13 букв: 145 слов\n",
            "  14 букв: 75 слов\n",
            "  15 букв: 43 слов\n",
            "  16 букв: 27 слов\n",
            "  17 букв: 15 слов\n",
            "  18 букв: 9 слов\n",
            "  19 букв: 11 слов\n",
            "  20 букв: 4 слов\n",
            "  21 букв: 2 слов\n",
            "  22 букв: 3 слов\n",
            "  23 букв: 1 слов\n",
            "  24 букв: 1 слов\n",
            "  25 букв: 3 слов\n",
            "  26 букв: 1 слов\n",
            "  27 букв: 2 слов\n",
            "  28 букв: 2 слов\n",
            "  33 букв: 1 слов\n",
            "  51 букв: 1 слов\n",
            "  98 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words2)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "for word in all_cleaned_words2:\n",
        "    word_lengths.append(len(word))\n",
        "    total_chars += len(word)\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "#                если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "  if length in word_length_count:\n",
        "    word_length_count[length] += 1\n",
        "#                иначе: выполняем >\n",
        "  else:\n",
        "    word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ST2kvv0_7RI",
        "outputId": "0b87fc3d-06a7-4f2b-f57b-8fe11f2d510c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3153343\n",
            "Символов после очистки: 12584255\n",
            "Распределение длин слов:\n",
            "  1 букв: 174489 слов\n",
            "  2 букв: 545330 слов\n",
            "  3 букв: 729280 слов\n",
            "  4 букв: 739869 слов\n",
            "  5 букв: 386784 слов\n",
            "  6 букв: 220018 слов\n",
            "  7 букв: 159386 слов\n",
            "  8 букв: 88176 слов\n",
            "  9 букв: 53683 слов\n",
            "  10 букв: 30381 слов\n",
            "  11 букв: 13295 слов\n",
            "  12 букв: 6740 слов\n",
            "  13 букв: 3303 слов\n",
            "  14 букв: 1366 слов\n",
            "  15 букв: 574 слов\n",
            "  16 букв: 308 слов\n",
            "  17 букв: 131 слов\n",
            "  18 букв: 81 слов\n",
            "  19 букв: 41 слов\n",
            "  20 букв: 25 слов\n",
            "  21 букв: 22 слов\n",
            "  22 букв: 9 слов\n",
            "  23 букв: 14 слов\n",
            "  24 букв: 13 слов\n",
            "  25 букв: 9 слов\n",
            "  26 букв: 1 слов\n",
            "  27 букв: 5 слов\n",
            "  29 букв: 1 слов\n",
            "  30 букв: 4 слов\n",
            "  34 букв: 2 слов\n",
            "  35 букв: 2 слов\n",
            "  38 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words3)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "for word in all_cleaned_words3:\n",
        "    word_lengths.append(len(word))\n",
        "    total_chars += len(word)\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "#                если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "  if length in word_length_count:\n",
        "    word_length_count[length] += 1\n",
        "#                иначе: выполняем >\n",
        "  else:\n",
        "    word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HPqOHxL__WO",
        "outputId": "a46ff441-2c3e-44b3-d600-60322b85e486"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3927654\n",
            "Символов после очистки: 14403360\n",
            "Распределение длин слов:\n",
            "  1 букв: 294340 слов\n",
            "  2 букв: 752699 слов\n",
            "  3 букв: 971475 слов\n",
            "  4 букв: 941998 слов\n",
            "  5 букв: 436215 слов\n",
            "  6 букв: 238371 слов\n",
            "  7 букв: 148023 слов\n",
            "  8 букв: 74303 слов\n",
            "  9 букв: 41612 слов\n",
            "  10 букв: 18211 слов\n",
            "  11 букв: 5781 слов\n",
            "  12 букв: 2915 слов\n",
            "  13 букв: 1102 слов\n",
            "  14 букв: 273 слов\n",
            "  15 букв: 52 слов\n",
            "  16 букв: 18 слов\n",
            "  17 букв: 62 слов\n",
            "  18 букв: 21 слов\n",
            "  19 букв: 182 слов\n",
            "  24 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words4)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "for word in all_cleaned_words4:\n",
        "    word_lengths.append(len(word))\n",
        "    total_chars += len(word)\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "#                если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "  if length in word_length_count:\n",
        "    word_length_count[length] += 1\n",
        "#                иначе: выполняем >\n",
        "  else:\n",
        "    word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctcQIQkAACmZ",
        "outputId": "58c2c4e1-f58e-4442-d86d-1dd3e9c3e6e5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3586641\n",
            "Символов после очистки: 14321921\n",
            "Распределение длин слов:\n",
            "  1 букв: 194418 слов\n",
            "  2 букв: 626804 слов\n",
            "  3 букв: 859941 слов\n",
            "  4 букв: 837927 слов\n",
            "  5 букв: 414679 слов\n",
            "  6 букв: 248885 слов\n",
            "  7 букв: 171208 слов\n",
            "  8 букв: 99706 слов\n",
            "  9 букв: 59181 слов\n",
            "  10 букв: 33513 слов\n",
            "  11 букв: 16130 слов\n",
            "  12 букв: 10162 слов\n",
            "  13 букв: 5425 слов\n",
            "  14 букв: 3199 слов\n",
            "  15 букв: 1817 слов\n",
            "  16 букв: 1203 слов\n",
            "  17 букв: 627 слов\n",
            "  18 букв: 525 слов\n",
            "  19 букв: 290 слов\n",
            "  20 букв: 234 слов\n",
            "  21 букв: 154 слов\n",
            "  22 букв: 124 слов\n",
            "  23 букв: 88 слов\n",
            "  24 букв: 80 слов\n",
            "  25 букв: 49 слов\n",
            "  26 букв: 39 слов\n",
            "  27 букв: 37 слов\n",
            "  28 букв: 27 слов\n",
            "  29 букв: 25 слов\n",
            "  30 букв: 20 слов\n",
            "  31 букв: 10 слов\n",
            "  32 букв: 15 слов\n",
            "  33 букв: 13 слов\n",
            "  34 букв: 10 слов\n",
            "  35 букв: 16 слов\n",
            "  36 букв: 7 слов\n",
            "  37 букв: 2 слов\n",
            "  38 букв: 1 слов\n",
            "  39 букв: 6 слов\n",
            "  40 букв: 3 слов\n",
            "  41 букв: 2 слов\n",
            "  42 букв: 4 слов\n",
            "  43 букв: 2 слов\n",
            "  44 букв: 2 слов\n",
            "  45 букв: 5 слов\n",
            "  47 букв: 2 слов\n",
            "  48 букв: 4 слов\n",
            "  49 букв: 1 слов\n",
            "  51 букв: 2 слов\n",
            "  53 букв: 1 слов\n",
            "  54 букв: 1 слов\n",
            "  56 букв: 1 слов\n",
            "  58 букв: 1 слов\n",
            "  59 букв: 3 слов\n",
            "  60 букв: 3 слов\n",
            "  63 букв: 1 слов\n",
            "  65 букв: 2 слов\n",
            "  66 букв: 1 слов\n",
            "  105 букв: 2 слов\n",
            "  114 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 2: частотность слов"
      ],
      "metadata": {
        "id": "gFZj9nmSeSGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "for word in all_cleaned_words0:\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "  if word in word_frequency:\n",
        "    word_frequency[word] += 1\n",
        "# иначе\n",
        "  else:\n",
        "    word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words0 = set(all_cleaned_words0)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12uZ3UlLDSJv",
        "outputId": "8dd08666-7639-4c78-a7f7-990e0c927bc8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-10 самых частых слов:\n",
            "  1. 'i': 3970 раз\n",
            "  2. 'the': 2918 раз\n",
            "  3. 'to': 2578 раз\n",
            "  4. 'you': 2307 раз\n",
            "  5. 'a': 2054 раз\n",
            "  6. 'and': 1658 раз\n",
            "  7. 'it': 1472 раз\n",
            "  8. 'my': 1197 раз\n",
            "  9. 'in': 1169 раз\n",
            "  10. 'that': 1167 раз\n",
            "\n",
            "Всего уникальных слов: 11189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "for word in all_cleaned_words1:\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "  if word in word_frequency:\n",
        "    word_frequency[word] += 1\n",
        "# иначе\n",
        "  else:\n",
        "    word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words1 = set(all_cleaned_words1)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBx0yj0JBMEF",
        "outputId": "79268da7-48af-4822-81f7-ec2d18ecafe3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-10 самых частых слов:\n",
            "  1. 'i': 3970 раз\n",
            "  2. 'the': 2918 раз\n",
            "  3. 'to': 2578 раз\n",
            "  4. 'you': 2307 раз\n",
            "  5. 'a': 2054 раз\n",
            "  6. 'and': 1658 раз\n",
            "  7. 'it': 1472 раз\n",
            "  8. 'my': 1197 раз\n",
            "  9. 'in': 1169 раз\n",
            "  10. 'that': 1167 раз\n",
            "\n",
            "Всего уникальных слов: 11193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "for word in all_cleaned_words2:\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "  if word in word_frequency:\n",
        "    word_frequency[word] += 1\n",
        "# иначе\n",
        "  else:\n",
        "    word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words2 = set(all_cleaned_words2)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words2)}\")"
      ],
      "metadata": {
        "id": "7YHAAcg1Bbzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "for word in all_cleaned_words3:\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "  if word in word_frequency:\n",
        "    word_frequency[word] += 1\n",
        "# иначе\n",
        "  else:\n",
        "    word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words3 = set(all_cleaned_words3)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "eIguFhoEB8vZ",
        "outputId": "d71088c5-64f0-4f21-9fd0-3ced94990669"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1929648155.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_count_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_count_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword_count_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mword_count_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Меняем местами\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_count_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "for word in all_cleaned_words4:\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "  if word in word_frequency:\n",
        "    word_frequency[word] += 1\n",
        "# иначе\n",
        "  else:\n",
        "    word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words4 = set(all_cleaned_words4)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words4)}\")"
      ],
      "metadata": {
        "id": "C7-HFL0rCDEE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}