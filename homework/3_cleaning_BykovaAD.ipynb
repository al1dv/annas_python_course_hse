{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vifirsanova/hse-python-course/blob/main/workbook/3_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl6M3rDU5XhG"
      },
      "source": [
        "**Data Cleaning** (чистка данных) - этап предварительной обработки данных для анализа данных и машинного обучения.\n",
        "\n",
        "**Примеры Data Cleaning:**\n",
        "- удаление избыточных столбцов из табличных данных;\n",
        "- приведение текста к нижнему регистру;\n",
        "- чистка текста от HTML-артефактов\n",
        "\n",
        "Загрузим тренировочный датасет, почистим его и проанализируем результаты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK_zsNv26Tsk"
      },
      "source": [
        "# Задание 1: Загрузка данных\n",
        "\n",
        "Загрузим тренировочный датасет и посмотрим на наши данные.\n",
        "\n",
        "Представим, что мы загрузили статью в формате HTML.\n",
        "\n",
        "Скачаем ее и выведем на экран первые 100 символов с помощью слайсинга (среза)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbak8zIx8i6_",
        "outputId": "ef0a0bd4-9a25-49e6-ed2a-819f0e6c697b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-25 11:09:59--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/data_cleaning.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2377 (2.3K) [text/plain]\n",
            "Saving to: ‘data_cleaning.txt’\n",
            "\n",
            "data_cleaning.txt   100%[===================>]   2.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-25 11:10:00 (29.1 MB/s) - ‘data_cleaning.txt’ saved [2377/2377]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# загружаем тренировочные данные\n",
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/data_cleaning.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OJ68oc8E8r9P"
      },
      "outputs": [],
      "source": [
        "# запишем данные в переменную data\n",
        "with open('data_cleaning.txt', 'r') as f:\n",
        "  data = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ9GtP8s86V8",
        "outputId": "129513c4-d6c1-4364-a43d-e8ba4e5811d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>Sample HTML Document</title>\n",
            "</head>\n",
            "<body>\n",
            "    <h1>Welcome\n"
          ]
        }
      ],
      "source": [
        "# выведите на экран первые 100 символов с помощью слайсинга\n",
        "\n",
        "### ваш код здесь ###\n",
        "short_text = data[:100]\n",
        "print(short_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIGQ9xGQ6t1U"
      },
      "source": [
        "# Задание 2: Удаление артефактов\n",
        "\n",
        "В данных много артефактов - HTML-тегов.\n",
        "\n",
        "Удалим HTML-артефакты с помощью регулярных выражений RegEx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aQ0ka1oq9uVz"
      },
      "outputs": [],
      "source": [
        "# пропишем паттерн для поиска HTML-тегов вида <tag> ... </tag>\n",
        "import re   # загрузим библиотеку для обработки регулярных выражений\n",
        "\n",
        "tag_pattern = r'<[^>]+>'    # паттерн для поиска тегов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8oleHAo_UaY"
      },
      "source": [
        "Используйте функцию `re.sub` (substitution) для чистки данных\n",
        "\n",
        "`re.sub` ищет в строке `string` соответствия RegEx-паттерну `pattern` и меняет найденное на указанную строку `repl`\n",
        "\n",
        "Как используем функцию: `re.sub(pattern, repl, string)`\n",
        "\n",
        "- `pattern` - паттерн RegEx, соответствия которому будет искать функция\n",
        "- `repl` - на что будем менять найденные соответствия\n",
        "- `string` - где будем искать, наш датасет\n",
        "\n",
        "Запишите результат в переменную `clean_text` и выведите на экран с 720-го по 800-ый символ очищенного текста\n",
        "\n",
        "Используйте слайсинг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjqjGi8P-H6O",
        "outputId": "eeee5657-d31e-4aca-d1ec-8f1f9b52ae30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "owercase or uppercase. \n",
            "     It's crucial to handle  HTML entities  such as &lt;\n"
          ]
        }
      ],
      "source": [
        "# Подсказки:\n",
        "# используйте паттерн, записанный в переменную tag_pattern\n",
        "# замените результат на пустую строку \"\"\n",
        "### ваш код здесь: примените re.sub ###\n",
        "clean_text = re.sub(tag_pattern, \" \", data)\n",
        "### ваш код здесь: выведите результат с 720-го по 800-ый символ ###\n",
        "print(clean_text[720:800])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZAWGBC7Ajr7"
      },
      "source": [
        "Мы удалили не все специальные символы HTML\n",
        "\n",
        "Создадим еще один паттерн и повторим процедуру"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIftruIgBuQj"
      },
      "outputs": [],
      "source": [
        "symbols_pattern = r'&\\w+;'    # паттерн для поиска специальных символов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ19ehiFB5d6"
      },
      "source": [
        "Используйте `re.sub` для удаления этих символов\n",
        "\n",
        "Теперь функция принимает на вход паттерн `symbols_pattern` и текст `clean_text`\n",
        "\n",
        "Перезапишите переменную `clean_text`\n",
        "\n",
        "Выведите на экран с 720-го по 800-ый символ, чтобы убедиться в том, что чистка прошла успешно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsX39hWDCLR6",
        "outputId": "b531ff90-87aa-491f-bec3-82ad09d9f638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tandardize the text case to ensure consistency in the dataset. This can be achie\n"
          ]
        }
      ],
      "source": [
        "### ваш код здесь: примените re.sub ###\n",
        "clean_text = re.sub(symbols_pattern, \" \", clean_text)\n",
        "### ваш код здесь: выведите результат с 720-го по 800-ый символ ###\n",
        "print(clean_data[720:800])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP70Rf3oCKNZ"
      },
      "source": [
        "В нашем тексте остались двойные пробелы\n",
        "\n",
        "Уберем им с помощью очередного паттерна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GMGJDpaEDHx5",
        "outputId": "bb5e2c86-def1-4495-f402-22beec03d204"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' \\n \\n \\n     Sample HTML Document \\n \\n \\n     Welcome to Data Cleaning \\n     This is a sample paragraph '"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# выведите на экран первые 100 символов вашего текущего результата\n",
        "# на этот раз не используйте print\n",
        "### ваш код здесь\n",
        "clean_text[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpgXBzMxDicX"
      },
      "source": [
        "Создаем паттерн для поиска двойных пробелов\n",
        "\n",
        "Повторите процедуру, перезапишите результат в `clean_text` и выведите первые 100 символов\n",
        "\n",
        "Что мы запишем в переменную `repl`, чтобы не удалить абсолютно все пробелы?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aQ-ZqbEcDcIE",
        "outputId": "2e609be3-e417-4b9b-cef4-507156b67367"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Sample HTML Document Welcome to Data Cleaning This is a sample paragraph with HTML artifacts such a'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "space_pattern = r'\\s+'\n",
        "\n",
        "### ваш код здесь: примените re.sub ###\n",
        "clean_text = re.sub(space_pattern, \" \", clean_text)\n",
        "### ваш код здесь: выведите первые 100 символов, не используя print ###\n",
        "clean_text[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwtj4l2x6bwS"
      },
      "source": [
        "# Задание 3: Смена регистра\n",
        "\n",
        "Приведем все слова к нижнему регистру с помощью функции `lower`\n",
        "\n",
        "Запишем результат в переменную `text_lower` и выведем на экран последние 100 символов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbmH8JL0EPeg",
        "outputId": "884199df-9871-41fd-ae3c-1f4caab40f9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'e learning models, making predictions, or generating insights to support decision-making processes. '"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### ваш код здесь: примените lower к clean_text ###\n",
        "text_lower = clean_text.lower()\n",
        "### ваш код здесь: выведите первые 100 символов с конца, используйте слайсинг и не забудьте про - ###\n",
        "text_lower[-100:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkxdtN1Q6mwU"
      },
      "source": [
        "# Задание 4: Удаление стоп-слов\n",
        "\n",
        "Удалим частотные слова, которые создают шум для решения задач\n",
        "\n",
        "Загрузим список стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ypsKpKBE6T-",
        "outputId": "feea762c-2265-4b84-c620-26883d3e6277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-25 11:47:14--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 954 [text/plain]\n",
            "Saving to: ‘stopwords.txt’\n",
            "\n",
            "\rstopwords.txt         0%[                    ]       0  --.-KB/s               \rstopwords.txt       100%[===================>]     954  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-25 11:47:15 (39.3 MB/s) - ‘stopwords.txt’ saved [954/954]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_c1xfdkgFNcg"
      },
      "outputs": [],
      "source": [
        "# запишем данные в переменную stopwords\n",
        "with open('stopwords.txt', 'r') as f:\n",
        "  stopwords = f.read().split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nansznnrFVN-"
      },
      "source": [
        "Выведите на экран первые 10 стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pctau5NgFYJG",
        "outputId": "40354e7e-842b-42a2-a40a-06d604e50122"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### ваш код здесь ###\n",
        "stopwords[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C4R5y63Fqrl"
      },
      "source": [
        "С помощью `random` мы можем \"вытянуть\" из списка стоп-слов случайное слово"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8SX-lcCAFjNc",
        "outputId": "a2dd88b9-da4e-48a8-b628-2bebaf9b9aed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"won't\""
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "random.choice(stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPDPQYYTFwsM"
      },
      "source": [
        "\"Вытяните\" еще одно случайное слово и запишите его в переменную `random_word`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "oJkDb27LF75t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "them\n"
          ]
        }
      ],
      "source": [
        "### ваш код здесь ###\n",
        "random_word = random.choice(stopwords)\n",
        "print(random_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erv_tjszGZlo"
      },
      "source": [
        "Проверьте, есть ли это слово в `text_lower` с помощью `in`\n",
        "\n",
        "Выведите на экран это слово"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2NJtaSOGBDT",
        "outputId": "032b2982-b5c1-41f8-fe7a-abcefa1d00cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Результат проверки False\n",
            "Случайное слово: them\n"
          ]
        }
      ],
      "source": [
        "### ваш код здесь: вывод на экран текста \"Результат проверки:\" и проверки с in ###\n",
        "print('Результат проверки', random_word in text_lower)\n",
        "### ваш код здесь: вывод текста \"Случайное слово:\" и random_word ###\n",
        "print('Случайное слово:', random_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBJJHLvrHCCO"
      },
      "source": [
        "Попробуйте сгенерировать еще несколько слов и проверить их наличие в `text_lower`\n",
        "\n",
        "Для этого запустите повторно две последние ячейки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "gY7oeXTXGW0D",
        "outputId": "29a5fe30-9fd3-447b-9de7-5ed01589fdd4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' s mple html  cu nt  lco    d t  cle n ng t   s   s mple p r gr ph w th html  rt f cts    s bold  nd  t l c text. d t  cle n ng  s  n essent  l process  n prep r ng d t     n lys s.  t  nvolves v r ous techn ques   cle n, tr ns m,  nd preprocess d t .  n d t  cle n ng,  t\\'s  mp t nt   remove s p w ds l ke \"t \", \" nd\", \" \", etc. s p w ds  re comm  w ds th t  re  ten f ltered     text d t   c use t y    t c rry s gn f c nt   n ng.  re\\'s   t r p r gr ph.   t  s text  s  n  perc se   lo rc se.  t\\'s  mp t nt   st nd rd ze t  text c se   ensure c s stency  n t  d t set. t  c n    ch eved   c vert ng  ll text   lo rc se    perc se.  t\\'s cruc  l   h ndle html ent t es    s d v, p, , etc. html ent t es  re spec  l ch r cters   symbols th t h ve spec f c   n ngs  n html. t y need     properly h ndled    vo d  ssues   d t  process ng. d t  cle n ng  l   nvolves de l ng w th m ss ng v lues. m ss ng v lues c n occur due   v r ous re s s    s  ncomplete d t  collect     d t  entry err s.  t\\'s essent  l    dent fy  nd h ndle m ss ng v lues  ppropr  tely    vo d b  s  n t   n lys s. text d t   ten c t  ns   se    s punctu t   m rks, spec  l ch r cters,  nd d g ts. remov ng   se   text d t   s necess ry   focus   t    n ngful c tent. techn ques    s regul r express  s c n   used     se remov l.   t r  mp t nt  spect   d t  cle n ng  s ded l c t  . d l c te rec ds  n   d t set c n skew  n lys s results  nd le d    n ccur te c clus  s.  dent fy ng  nd remov ng d l c te rec ds ensures d t   ntegr ty  nd  mproves t  qu l ty    n lys s.  fter cle n ng t  d t ,  t\\'s essent  l   per m expl  t y d t   n lys s (ed )   g  n  ns ghts  nd  dent fy p tterns. ed   nvolves v su l z ng d t , comput ng summ ry st t st cs,  nd expl  ng rel t  sh ps  t en v r  bles.  ce t  d t   s cle ned  nd  n lyzed,  t c n   used   v r ous purposes    s bu ld ng m ch ne le rn ng models, m k ng pred ct  s,   gener t ng  ns ghts   s p t dec s  -m k ng processes. '"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Вот так будет выглядеть текст после удаления стоп-слов _без_ токенизации\n",
        "Заменятся все аналогичные сочетания знаков\n",
        "Поэтому перед _удалением_ стоп-слов, проведем токенизацию\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mepvb0Kw7Ncq"
      },
      "source": [
        "# Задание 5: Токенизация\n",
        "\n",
        "Токенизируем датасет для дальнейшей работы\n",
        "\n",
        "Создадим 2 набора токенов: с сегментацией по предложениям и с сегментацией по словам"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me63a7SNLa6C"
      },
      "source": [
        "Создайте переменную `sentences`\n",
        "\n",
        "С помощью `split` разделите текст на предложения (сегменты, разделенные знаком `.`)\n",
        "\n",
        "Выведите на экран первые 10 элементов `sentences`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G13fM_27M1t",
        "outputId": "5238ef6b-7c2d-4bc2-e052-28d263da20ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[' sample html document welcome to data cleaning this is a sample paragraph with html artifacts such as bold and italic text', ' data cleaning is an essential process in preparing data for analysis', ' it involves various techniques to clean, transform, and preprocess data', ' in data cleaning, it\\'s important to remove stop words like \"the\", \"and\", \"of\", etc', ' stop words are common words that are often filtered out from text data because they do not carry significant meaning', \" here's another paragraph\", ' sometimes text is in uppercase or lowercase ', \" it's important to standardize the text case to ensure consistency in the dataset\", ' this can be achieved by converting all text to lowercase or uppercase', \" it's crucial to handle html entities such as div , p , , etc\"]\n"
          ]
        }
      ],
      "source": [
        "### ваш код здесь: split для сегментации по знаку `.` ###\n",
        "sentences = text_lower.split('.')\n",
        "### вывод на экран первых 10 предложений ###\n",
        "print(sentences[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J_C8cq0L2rB"
      },
      "source": [
        "Создайте переменную `tokens`\n",
        "\n",
        "С помощью `split` разделите текст `text_lower` на слова\n",
        "\n",
        "Выведите первые 10 элементов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj3dXh576a5A",
        "outputId": "0d6920c5-a457-4ef2-ca3f-f86c2c6aaf02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', 'sample', 'html', 'document', 'welcome', 'to', 'data', 'cleaning', 'this', 'is']\n"
          ]
        }
      ],
      "source": [
        "### ваш код здесь: split для сегментации по пробелу ###\n",
        "tokens = text_lower.split(' ')\n",
        "### ваш код здесь: вывод на экран первых 10 слов ###\n",
        "print(tokens[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q7FfNK9MJ_K"
      },
      "source": [
        " Удалим стоп-слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMy-_DNJ0HF3",
        "outputId": "c4fcd19a-949d-4c5c-d7a2-c93a422eac07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', 'sample', 'html', 'document', 'welcome', 'data', 'cleaning', 'sample', 'paragraph', 'html']\n"
          ]
        }
      ],
      "source": [
        "clean_tokens = []\n",
        "\n",
        "for token in tokens:  # итерация по списку токенов tokens\n",
        "  if token not in stopwords:  # проверяем отсутствие токена в списке стоп-слов\n",
        "    clean_tokens.append(token)  # добавляем токен в новый очищенный список токенов, если его нет в стоп-словах\n",
        "\n",
        "### ваш код здесь: вывод на экран первых 10 элементов clean_tokens ###\n",
        "print(clean_tokens[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EYfMpHZNUkA"
      },
      "source": [
        "# И еще одно задание...\n",
        "\n",
        "В ячейке ниже вы сможете загрузить еще один текст\n",
        "\n",
        "Используйте свой код и код из задания, чтобы\n",
        "\n",
        "1. удалить артефакты (html-теги, специальные символы и двойные пробелы)\n",
        "\n",
        "2. привести текст к нижнему регистру\n",
        "\n",
        "3. токенизировать текст по предложениям\n",
        "\n",
        "4. токенизировать текст по словам\n",
        "\n",
        "5. удалить стоп-слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE6b-OKsNqK_",
        "outputId": "4735ce90-f57f-44b7-90e3-e091005413b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-25 12:26:33--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/extracurricular/artefacts.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 845 [text/plain]\n",
            "Saving to: ‘artefacts.txt’\n",
            "\n",
            "\rartefacts.txt         0%[                    ]       0  --.-KB/s               \rartefacts.txt       100%[===================>]     845  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-25 12:26:33 (30.2 MB/s) - ‘artefacts.txt’ saved [845/845]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/extracurricular/artefacts.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "CT7eVLpHOMTQ"
      },
      "outputs": [],
      "source": [
        "# запишем данные в переменную artefacts\n",
        "with open('artefacts.txt', 'r') as f:\n",
        "  artefacts = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9g-geUOsORlM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Первые 5 предложений: [' sample web page welcome to our website this is some sample text on our website', ' you can contact us at info@example', 'com', ' latest news breaking news: important announcement lorem ipsum dolor sit amet, consectetur adipiscing elit', ' vivamus lacinia, arcu in fermentum tincidunt'] \n",
            " Первые 10 слов: ['', 'sample', 'web', 'page', 'welcome', 'to', 'our', 'website', 'this', 'is'] \n",
            " Первые 10 очищенных токенов: ['', 'sample', 'web', 'page', 'welcome', 'website', 'sample', 'text', 'website.', 'can']\n"
          ]
        }
      ],
      "source": [
        "### ваш код в ячейках ниже ###\n",
        "tag_pattern = r'<[^>]+>'\n",
        "clean_new_text = re.sub(tag_pattern, \"\", artefacts)\n",
        "symbols_pattern = r'&\\w+;'\n",
        "clean_new_text = re.sub(symbols_pattern, \"\", clean_new_text)\n",
        "space_pattern = r'\\s+'\n",
        "clean_new_text = re.sub(space_pattern, \" \", clean_new_text)\n",
        "new_text_lower = clean_new_text.lower()\n",
        "sentences = new_text_lower.split('.')\n",
        "tokens = new_text_lower.split(' ')\n",
        "clean_tokens = []\n",
        "for token in tokens:\n",
        "  if token not in stopwords:\n",
        "    clean_tokens.append(token)\n",
        "print('Первые 5 предложений:', sentences[:5], '\\n', 'Первые 10 слов:', tokens[:10], '\\n', 'Первые 10 очищенных токенов:', clean_tokens[:10])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOLOE0Z8VyFp76LQAc2njcJ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
